{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the second project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Reacher.app\"`\n",
    "- **Windows** (x86): `\"path/to/Reacher_Windows_x86/Reacher.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Reacher_Windows_x86_64/Reacher.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Reacher_Linux/Reacher.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Reacher_Linux/Reacher.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Reacher.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Reacher.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "#env = UnityEnvironment(file_name='C:\\\\Users\\\\kvjos\\\\udacityRL\\\\deep-reinforcement-learning\\\\p2_continuous-control\\\\Reacher_Windows_x86_64/Reacher.exe')\n",
    "env = UnityEnvironment(file_name='Reacher.app')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, a double-jointed arm can move to target locations. A reward of `+0.1` is provided for each step that the agent's hand is in the goal location. Thus, the goal of your agent is to maintain its position at the target location for as many time steps as possible.\n",
    "\n",
    "The observation space consists of `33` variables corresponding to position, rotation, velocity, and angular velocities of the arm.  Each action is a vector with four numbers, corresponding to torque applicable to two joints.  Every entry in the action vector must be a number between `-1` and `1`.\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: 0.13799999691545964\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "for i in range(1000):\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = np.array([1 if t else 0 for t in env_info.local_done])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rewards = np.zeros(20)\n",
    "episode_rewards = []\n",
    "for i, terminal in enumerate(terms):\n",
    "                if terms[i]:\n",
    "                    self.episode_rewards.append(self.all_rewards[i])\n",
    "                    self.all_rewards[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episode_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Try just understanding the training segment of PPO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "for i in range(1000):\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout = []\n",
    "rollout_length = 60\n",
    "env_info = env.reset(train_mode=True)[brain_name]    \n",
    "states = env_info.vector_observations\n",
    "for _ in range(rollout_length):\n",
    "    actions, log_probs, _, values = policy(states)\n",
    "    env_info = env.step(actions.cpu().detach().numpy())[brain_name]\n",
    "    next_states = env_info.vector_observations\n",
    "    rewards = env_info.rewards\n",
    "    terminals = np.array([1 if t else 0 for t in env_info.local_done])\n",
    "    #self.all_rewards += rewards\n",
    "            \n",
    "    #for i, terminal in enumerate(terminals):\n",
    "        #if terminals[i]:\n",
    "            #self.episode_rewards.append(self.all_rewards[i])\n",
    "            #self.all_rewards[i] = 0\n",
    "    \n",
    "    rollout.append([states, values.detach(), actions.detach(), log_probs.detach(), rewards, 1 - terminals])\n",
    "    states = next_states\n",
    "\n",
    "pending_value = policy(states)[-1]\n",
    "rollout.append([states, pending_value, None, None, None, None])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.019999999552965164, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.03999999910593033, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.03999999910593033, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.03999999910593033, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.03999999910593033, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.03999999910593033, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.03999999910593033, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.03999999910593033, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.03999999910593033, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.019999999552965164, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(rollout_length):\n",
    "    print(rollout[i][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_rollout = [None] * (len(rollout) - 1)\n",
    "advantages = torch.Tensor(np.zeros((20, 1)))\n",
    "returns = pending_value.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2105],\n",
       "        [-0.2466],\n",
       "        [-0.1758],\n",
       "        [-0.2399],\n",
       "        [-0.1876],\n",
       "        [-0.1743],\n",
       "        [-0.0614],\n",
       "        [-0.2716],\n",
       "        [-0.6308],\n",
       "        [-0.1964],\n",
       "        [-0.1475],\n",
       "        [-0.1580],\n",
       "        [-0.1890],\n",
       "        [ 0.0733],\n",
       "        [-0.3741],\n",
       "        [-0.0109],\n",
       "        [-0.1138],\n",
       "        [-0.3361],\n",
       "        [-0.3716],\n",
       "        [-0.2445]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rewards 59[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 58[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 57[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 56[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 55[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 54[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 53[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 52[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 51[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 50[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 49[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 48[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 47[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 46[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 45[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 44[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 43[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 42[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 41[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 40[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 39[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 38[0.0, 0.019999999552965164, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor(1.00000e-02 *\n",
      "       [[ 0.0000],\n",
      "        [ 2.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000]])\n",
      "Rewards 37[0.0, 0.03999999910593033, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor(1.00000e-02 *\n",
      "       [[ 0.0000],\n",
      "        [ 4.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000]])\n",
      "Rewards 36[0.0, 0.03999999910593033, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor(1.00000e-02 *\n",
      "       [[ 0.0000],\n",
      "        [ 4.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000]])\n",
      "Rewards 35[0.0, 0.03999999910593033, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor(1.00000e-02 *\n",
      "       [[ 0.0000],\n",
      "        [ 4.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000]])\n",
      "Rewards 34[0.0, 0.03999999910593033, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor(1.00000e-02 *\n",
      "       [[ 0.0000],\n",
      "        [ 4.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000]])\n",
      "Rewards 33[0.0, 0.03999999910593033, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor(1.00000e-02 *\n",
      "       [[ 0.0000],\n",
      "        [ 4.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000]])\n",
      "Rewards 32[0.0, 0.03999999910593033, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor(1.00000e-02 *\n",
      "       [[ 0.0000],\n",
      "        [ 4.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000]])\n",
      "Rewards 31[0.0, 0.03999999910593033, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor(1.00000e-02 *\n",
      "       [[ 0.0000],\n",
      "        [ 4.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000]])\n",
      "Rewards 30[0.0, 0.03999999910593033, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor(1.00000e-02 *\n",
      "       [[ 0.0000],\n",
      "        [ 4.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000]])\n",
      "Rewards 29[0.0, 0.019999999552965164, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor(1.00000e-02 *\n",
      "       [[ 0.0000],\n",
      "        [ 2.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000]])\n",
      "Rewards 28[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 27[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 26[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 25[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 24[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 23[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 22[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 21[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 20[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 19[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 18[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 17[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 16[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 15[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 14[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 13[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 12[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 11[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 10[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 9[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 8[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 7[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 6[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 5[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 4[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 3[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 2[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 1[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n",
      "Rewards 0[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]])\n"
     ]
    }
   ],
   "source": [
    "for i in reversed(range(len(rollout) - 1)):\n",
    "    states, value, actions, log_probs, rewards, terminals = rollout[i]\n",
    "#    print(\"Rewards \" + str(i) + str(rewards))\n",
    "#    print(torch.Tensor(rewards).unsqueeze(1))\n",
    "     terminals = torch.Tensor(terminals).unsqueeze(1)\n",
    "     rewards = torch.Tensor(rewards).unsqueeze(1)\n",
    "    actions = torch.Tensor(actions)\n",
    "     states = torch.Tensor(states)\n",
    "        next_value = rollout[i + 1][1]\n",
    "#     returns = rewards + hyperparameters['discount_rate'] * terminals * returns\n",
    "\n",
    "#     td_error = rewards + hyperparameters['discount_rate'] * terminals * next_value.detach() - value.detach()\n",
    "#     advantages = advantages * hyperparameters['tau'] * hyperparameters['discount_rate'] * terminals + td_error\n",
    "#     processed_rollout[i] = [states, actions, log_probs, returns, advantages]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dist = torch.distributions.Normal(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    processed_rollout = [None] * (len(rollout) - 1)\n",
    "        advantages = torch.Tensor(np.zeros((self.config['environment']['number_of_agents'], 1)))\n",
    "        returns = pending_value.detach()\n",
    "        \n",
    "        states, actions, log_probs_old, returns, advantages = map(lambda x: torch.cat(x, dim=0), zip(*processed_rollout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.8027])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Policy(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Policy, self).__init__()\n",
    "     \n",
    "        self.size = 33\n",
    "        self.fc1 = nn.Linear(self.size, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 4)\n",
    "        \n",
    "        self.critic_fc1 = nn.Linear(self.size,512)\n",
    "        self.critic_fc2 = nn.Linear(512,128)\n",
    "        self.critic_fc3 = nn.Linear(128,1)\n",
    "        self.normalDistParams = torch.ones((1,4),device=device)\n",
    "        \n",
    "    def forward(self, x,sampled_actions=None):\n",
    "        a  = torch.Tensor(x)\n",
    "        a = F.relu(self.fc1(a))\n",
    "        a = F.relu(self.fc2(a))\n",
    "        a = F.tanh(self.fc3(a))\n",
    "        \n",
    "        v = torch.Tensor(x)\n",
    "        v = F.relu(self.critic_fc1(v))\n",
    "        v = F.relu(self.critic_fc2(v))\n",
    "        v = self.critic_fc3(v)\n",
    "        \n",
    "       \n",
    "        #x is now the mean of a normal distribution from which we\n",
    "        #sample the actual action values\n",
    "        prob_dists = torch.distributions.Normal(a,self.normalDistParams)\n",
    "        if sampled_actions is None:\n",
    "            sampled_actions = prob_dists.sample()\n",
    "        action_probabilities = prob_dists.log_prob(sampled_actions) #Prob of each individual action\n",
    "        summed_action_probabilities = torch.sum(action_probabilities,dim=-1,keepdim=True)\n",
    "        return sampled_actions,summed_action_probabilities,x,v\n",
    "        \n",
    "\n",
    "\n",
    "# run your own policy!\n",
    "policy=Policy().to(device)\n",
    "#policy=pong_utils.Policy().to(device)\n",
    "\n",
    "# we use the adam optimizer with learning rate 2e-4\n",
    "# optim.SGD is also possible\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(policy.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Policy(\n",
       "  (fc1): Linear(in_features=33, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=4, bias=True)\n",
       "  (critic_fc1): Linear(in_features=33, out_features=512, bias=True)\n",
       "  (critic_fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (critic_fc3): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_obs = torch.tensor(env_info.vector_observations,dtype=torch.float, device=device)\n",
    "test_actions,test_probs,dist_means,test_val = policy(test_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4196],\n",
       "        [-0.2368],\n",
       "        [ 0.0104],\n",
       "        [-0.2756],\n",
       "        [-0.1634],\n",
       "        [-0.3744],\n",
       "        [-0.4036],\n",
       "        [-0.3954],\n",
       "        [-0.2302],\n",
       "        [-0.2640],\n",
       "        [-0.0769],\n",
       "        [-0.4452],\n",
       "        [-0.3922],\n",
       "        [ 0.0270],\n",
       "        [-0.2938],\n",
       "        [-0.2137],\n",
       "        [-0.0689],\n",
       "        [-0.2956],\n",
       "        [-0.0984],\n",
       "        [ 0.0443]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-8.7777],\n",
       "        [-4.2433],\n",
       "        [-4.0453],\n",
       "        [-6.0767],\n",
       "        [-4.3547],\n",
       "        [-9.4517],\n",
       "        [-4.5175],\n",
       "        [-5.3599],\n",
       "        [-6.1033],\n",
       "        [-4.9137],\n",
       "        [-7.6580],\n",
       "        [-5.1190],\n",
       "        [-5.2781],\n",
       "        [-4.1189],\n",
       "        [-5.9885],\n",
       "        [-6.4951],\n",
       "        [-5.6233],\n",
       "        [-7.9179],\n",
       "        [-5.3300],\n",
       "        [-7.5236]], device='cuda:0', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: 0.17549999607726932\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "for i in range(1000):\n",
    "    #actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    #actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    states_tensor = torch.tensor(states,dtype=torch.float,device=device)\n",
    "    actions,act_probs,act_means = policy(states_tensor)\n",
    "    actions = actions.squeeze().cpu().detach().numpy()\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_trajectories(env,policy,tmax=200,nrand=5):\n",
    "    # number of parallel instances\n",
    "    #env_info = env.reset(train_mode=False)[brain_name]\n",
    "    #n=len(env_info.agents)\n",
    "\n",
    "    #initialize returning lists and start the game!\n",
    "    state_list=[]\n",
    "    reward_list=[]\n",
    "    prob_list=[]\n",
    "    action_list=[]\n",
    "\n",
    "    # start all parallel agents\n",
    "    #envs.step([1]*n)\n",
    "    \n",
    "    # perform nrand random steps\n",
    "    for _ in range(nrand):\n",
    "        actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "        actions = np.clip(actions, -1, 1)   \n",
    "        env_info = env.step(actions)[brain_name]\n",
    "    \n",
    "    for t in range(tmax):\n",
    "        states_tensor = torch.tensor(env_info.vector_observations,dtype=torch.float,device=device)\n",
    "        actions,probs,action_means = policy(states_tensor)\n",
    "        \n",
    "        actions = actions.squeeze().cpu().detach().numpy()\n",
    "        probs = probs.squeeze().cpu().detach().numpy()\n",
    "        action_means = action_means.squeeze().cpu().detach().numpy()\n",
    "        \n",
    "        env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "        next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "        rewards = env_info.rewards                         # get reward (for each agent)\n",
    "        dones = env_info.local_done                        # see if episode finished\n",
    "        states = next_states                               # roll over states to next time step\n",
    "        \n",
    "        state_list.append(states_tensor)\n",
    "        reward_list.append(rewards)\n",
    "        prob_list.append(probs)\n",
    "        action_list.append(actions)\n",
    "        \n",
    "        if np.any(dones):                                  # exit loop if episode finished\n",
    "            break\n",
    "\n",
    "    return prob_list, state_list, \\\n",
    "        action_list, reward_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs, test_states, test_actions, test_rewards = \\\n",
    "        collect_trajectories(env, policy, tmax=37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_normalized_rewards(rewards,discount=0.995):\n",
    "    discounts = discount**np.arange(len(rewards))\n",
    "    discounts_reshaped = discounts[:,np.newaxis]\n",
    "    rewards = np.asarray(rewards)\n",
    "    total_rewards = rewards*discounts_reshaped\n",
    "    #print(rewards)\n",
    "    #print(total_rewards)\n",
    "    future_rewards = np.flipud(np.cumsum(np.flipud(total_rewards),axis=0))\n",
    "    #print(\"Future rewards length = \" + str(len(future_rewards)))\n",
    "    \n",
    "    rewards_mean = np.mean(future_rewards,axis=1)\n",
    "    #print(rewards_mean)\n",
    "    rewards_std = np.std(future_rewards,axis=1) + 1e-10\n",
    "    rewards_normalized = (future_rewards-rewards_mean[:,np.newaxis])/(rewards_std[:,np.newaxis])\n",
    "    #print(rewards_normalized)\n",
    "    #print(\"Rewards normalize dlength : \" + str(len(rewards_normalized)) + \" \" + str(len(rewards_normalized[0])))\n",
    "    return rewards_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.019999999552965164, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03999999910593033, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03999999910593033, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03999999910593033, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03999999910593033, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03999999910593033, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03999999910593033, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03999999910593033, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03999999910593033, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03999999910593033, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03999999910593033, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03999999910593033, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03999999910593033, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03999999910593033, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03999999910593033, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573,  4.35889894,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573],\n",
       "       [-0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573,  4.35889894,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573],\n",
       "       [-0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573,  4.35889894,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573],\n",
       "       [-0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573,  4.35889894,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573],\n",
       "       [-0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573,  4.35889894,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573],\n",
       "       [-0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573,  4.35889894,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573],\n",
       "       [-0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573,  4.35889894,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573],\n",
       "       [-0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573,  4.35889894,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573],\n",
       "       [-0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573,  4.35889894,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573],\n",
       "       [-0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573,  4.35889894,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573],\n",
       "       [-0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573,  4.35889894,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573],\n",
       "       [-0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573,  4.35889894,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573],\n",
       "       [-0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573,  4.35889894,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573],\n",
       "       [-0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573,  4.35889894,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573],\n",
       "       [-0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573,  4.35889894,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573],\n",
       "       [-0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573,  4.35889894,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573],\n",
       "       [-0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573,  4.35889894,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573],\n",
       "       [-0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573,  4.35889894,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573],\n",
       "       [-0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573,  4.35889894,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573],\n",
       "       [-0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573,  4.35889894,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573],\n",
       "       [-0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573,  4.35889893,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573],\n",
       "       [-0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573,  4.35889893,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573],\n",
       "       [-0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573,  4.35889893,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573],\n",
       "       [-0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573,  4.35889892,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573],\n",
       "       [-0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573,  4.35889892,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573],\n",
       "       [-0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573,  4.35889889,\n",
       "        -0.22941573, -0.22941573, -0.22941573, -0.22941573, -0.22941573],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_rewards)\n",
    "calculate_normalized_rewards(test_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipped_surrogate(policy, old_probs, states, actions, rewards,\n",
    "                      discount = 0.995, epsilon=0.1, beta=0.01):\n",
    "\n",
    "    rewards_normalized = calculate_normalized_rewards(rewards)\n",
    "    \n",
    "    actions = torch.tensor(actions, dtype=torch.float, device=device)\n",
    "    old_probs = torch.tensor(old_probs, dtype=torch.float, device=device)\n",
    "    rewards = torch.tensor(rewards_normalized, dtype=torch.float, device=device)\n",
    "     \n",
    "    \n",
    "    # convert states to policy (or probability)\n",
    "    _,new_probs,_ = policy(torch.stack(states),actions)\n",
    "    new_probs = new_probs.squeeze()\n",
    "\n",
    "    #print(new_probs.shape)\n",
    "    #print(old_probs.shape)\n",
    "    \n",
    "    \n",
    "    #new_probs = torch.where(actions == pong_utils.RIGHT, new_probs, 1.0-new_probs)\n",
    "    \n",
    "    ratio = new_probs/old_probs\n",
    "    ratio = ratio.exp()\n",
    "    #print(ratio)\n",
    "    clipped_ratio = torch.clamp(ratio, 1-epsilon, 1+epsilon)\n",
    "    clipped_surrogate = torch.min(ratio*rewards, clipped_ratio*rewards)\n",
    "    #print(clipped_surrogate)\n",
    "    #print(old_probs)\n",
    "    #print(torch.log(old_probs+1.e-10))\n",
    "    # include a regularization term\n",
    "    # this steers new_policy towards 0.5\n",
    "    # prevents policy to become exactly 0 or 1 helps exploration\n",
    "    # add in 1.e-10 to avoid log(0) which gives nan\n",
    "    entropy = -(new_probs.exp()*torch.log(old_probs.exp()+1.e-10)+ (1.0-new_probs.exp())*torch.log(1.0-old_probs.exp()+1.e-10))\n",
    "    #print(entropy)\n",
    "    #return torch.mean(clipped_surrogate + beta*entropy)\n",
    "    return torch.mean(clipped_surrogate)\n",
    "    #return torch.mean(clipped_surrogate + beta*entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy=Policy().to(device)\n",
    "#policy=pong_utils.Policy().to(device)\n",
    "\n",
    "# we use the adam optimizer with learning rate 2e-4\n",
    "# optim.SGD is also possible\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(policy.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.2559, device='cuda:0', grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clipped_surrogate(policy,test_probs,test_states,test_actions,test_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkl-random 1.0.1 requires cython, which is not installed.\n",
      "You are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n",
      "training loop:   0% |                                          | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: progressbar in c:\\users\\kvjos\\anaconda3\\envs\\drlnd2\\lib\\site-packages (2.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   0% |                                           | ETA:  0:18:03\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4070, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4217, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4109, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4173, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   0% |                                           | ETA:  0:17:49\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4491, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4505, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4508, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4494, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   1% |                                           | ETA:  0:17:45\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4551, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4555, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4558, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4553, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   1% |                                           | ETA:  0:17:39\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4493, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4495, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4495, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4492, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   1% |                                           | ETA:  0:17:34\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3975, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3975, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3975, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3974, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   2% |                                           | ETA:  0:17:31\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4836, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4835, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4834, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4832, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   2% |#                                          | ETA:  0:17:28\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3873, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3872, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3872, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3871, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   2% |#                                          | ETA:  0:17:24\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3947, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3946, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3945, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3944, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   3% |#                                          | ETA:  0:17:21\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4237, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4237, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4236, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4235, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   3% |#                                          | ETA:  0:17:17\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2539, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2539, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2538, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2537, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Episode: 10, score: 0.097000\n",
      "[0.         0.         0.         0.         0.         0.84999998\n",
      " 0.         0.         0.         0.17       0.         0.\n",
      " 0.15       0.         0.51999999 0.         0.         0.24999999\n",
      " 0.         0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   3% |#                                          | ETA:  0:17:14\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1468, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1468, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1468, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1467, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   4% |#                                          | ETA:  0:17:11\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4454, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4453, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4451, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4449, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   4% |#                                          | ETA:  0:17:10\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2443, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2442, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2442, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2441, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   4% |##                                         | ETA:  0:17:06\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4164, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4163, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4161, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4160, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   5% |##                                         | ETA:  0:17:02\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4546, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4544, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4543, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4542, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   5% |##                                         | ETA:  0:16:58\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4743, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4741, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4739, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4737, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   5% |##                                         | ETA:  0:16:55\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4486, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4485, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4484, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4482, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   6% |##                                         | ETA:  0:16:51\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4322, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4321, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4320, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4318, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   6% |##                                         | ETA:  0:16:49\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3243, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3242, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3241, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3240, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   6% |##                                         | ETA:  0:16:47\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2827, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2826, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2825, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2824, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Episode: 20, score: 0.047000\n",
      "[0.         0.         0.         0.         0.21       0.\n",
      " 0.29999999 0.         0.         0.         0.         0.\n",
      " 0.07       0.         0.         0.35999999 0.         0.\n",
      " 0.         0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   7% |###                                        | ETA:  0:16:46\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2725, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2725, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2724, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2723, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   7% |###                                        | ETA:  0:16:44\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4320, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4319, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4318, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4316, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   7% |###                                        | ETA:  0:16:41\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3185, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3184, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3184, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3183, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   8% |###                                        | ETA:  0:16:39\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3206, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3206, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3205, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3204, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   8% |###                                        | ETA:  0:16:36\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1849, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1848, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1848, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1847, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   8% |###                                        | ETA:  0:16:32\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2885, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2885, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2884, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2883, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   9% |###                                        | ETA:  0:16:28\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1953, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1953, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1952, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1952, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   9% |####                                       | ETA:  0:16:24\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2889, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2888, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2887, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2886, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   9% |####                                       | ETA:  0:16:22\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2364, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2364, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2364, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2363, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  10% |####                                       | ETA:  0:16:19\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2564, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2563, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2563, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2562, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Episode: 30, score: 0.028500\n",
      "[0.         0.         0.         0.         0.         0.41999999\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.15       0.         0.         0.         0.\n",
      " 0.         0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  10% |####                                       | ETA:  0:16:18\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2030, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2030, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2029, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2028, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  10% |####                                       | ETA:  0:16:15\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0107, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0107, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0107, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0107, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  11% |####                                       | ETA:  0:16:11\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0210, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0210, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0210, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0210, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  11% |####                                       | ETA:  0:16:07\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1802, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1802, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1801, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1800, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  11% |#####                                      | ETA:  0:16:03\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2449, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2449, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2448, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2448, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  12% |#####                                      | ETA:  0:15:59\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0691, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0691, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0691, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0690, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  12% |#####                                      | ETA:  0:15:54\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3140, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3139, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3139, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3138, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  12% |#####                                      | ETA:  0:15:50\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2063, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2063, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2063, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2062, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  13% |#####                                      | ETA:  0:15:47\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2073, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2073, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2072, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2072, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  13% |#####                                      | ETA:  0:15:44\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1322, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1322, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1322, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1321, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Episode: 40, score: 0.006000\n",
      "[0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.12 0.   0.  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  13% |#####                                      | ETA:  0:15:40\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2294, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2294, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2293, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2292, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  14% |######                                     | ETA:  0:15:36\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4067, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4066, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4065, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4063, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  14% |######                                     | ETA:  0:15:31\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3695, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3695, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3693, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3692, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  14% |######                                     | ETA:  0:15:27\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3381, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3380, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3379, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3378, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  15% |######                                     | ETA:  0:15:23\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3363, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3363, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3362, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3360, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  15% |######                                     | ETA:  0:15:19\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1594, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1594, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1593, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1593, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  15% |######                                     | ETA:  0:15:15\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3744, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3744, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3743, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3741, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  16% |######                                     | ETA:  0:15:11\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2891, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2891, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2890, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2889, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  16% |#######                                    | ETA:  0:15:08\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  16% |#######                                    | ETA:  0:15:04\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2675, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2675, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2674, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2673, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Episode: 50, score: 0.029500\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.34999999 0.\n",
      " 0.         0.         0.         0.         0.23999999 0.\n",
      " 0.         0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  17% |#######                                    | ETA:  0:15:00\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3468, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3467, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3465, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3463, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  17% |#######                                    | ETA:  0:14:56\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2288, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2288, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2286, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2286, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  17% |#######                                    | ETA:  0:14:52\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2843, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2842, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2842, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2841, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  18% |#######                                    | ETA:  0:14:48\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2432, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2432, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2431, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2430, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  18% |#######                                    | ETA:  0:14:45\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3834, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3834, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3832, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3831, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  18% |########                                   | ETA:  0:14:41\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2194, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2194, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2193, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2192, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  19% |########                                   | ETA:  0:14:37\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3289, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3288, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3287, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3286, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  19% |########                                   | ETA:  0:14:33\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2786, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2785, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2785, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2784, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  19% |########                                   | ETA:  0:14:29\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1781, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1780, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1780, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1779, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  20% |########                                   | ETA:  0:14:26\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3980, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3979, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3977, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3975, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Episode: 60, score: 0.029500\n",
      "[0.   0.   0.   0.   0.   0.   0.   0.   0.   0.16 0.07 0.   0.   0.17\n",
      " 0.   0.   0.   0.   0.19 0.  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  20% |########                                   | ETA:  0:14:22\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0241, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0241, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0241, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0241, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  20% |########                                   | ETA:  0:14:19\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5006, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  21% |#########                                  | ETA:  0:14:15\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2027, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2028, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2026, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2025, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  21% |#########                                  | ETA:  0:14:11\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0301, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0301, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0301, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0301, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  21% |#########                                  | ETA:  0:14:08\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4014, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4013, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4012, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4010, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  22% |#########                                  | ETA:  0:14:04\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2294, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2293, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2292, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2292, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  22% |#########                                  | ETA:  0:14:00\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4114, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4113, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4112, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4110, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  22% |#########                                  | ETA:  0:13:57\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2423, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2423, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2422, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2421, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  23% |#########                                  | ETA:  0:13:53\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3174, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3173, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3172, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3172, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  23% |##########                                 | ETA:  0:13:49\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2232, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2232, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2231, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2230, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Episode: 70, score: 0.009500\n",
      "[0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.19 0.   0.   0.  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  23% |##########                                 | ETA:  0:13:46\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  24% |##########                                 | ETA:  0:13:42\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2707, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2707, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2706, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2705, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  24% |##########                                 | ETA:  0:13:39\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3011, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3010, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3009, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3008, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  24% |##########                                 | ETA:  0:13:35\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  25% |##########                                 | ETA:  0:13:32\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1868, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1867, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1867, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1866, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  25% |##########                                 | ETA:  0:13:28\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1107, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1106, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1106, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1105, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  25% |###########                                | ETA:  0:13:25\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3481, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3480, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3478, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3477, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  26% |###########                                | ETA:  0:13:21\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0826, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0826, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0826, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0825, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  26% |###########                                | ETA:  0:13:17\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2412, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2411, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2411, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2409, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  26% |###########                                | ETA:  0:13:14\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2305, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2305, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2304, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2303, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Episode: 80, score: 0.006000\n",
      "[0.   0.   0.   0.   0.   0.   0.   0.   0.12 0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  27% |###########                                | ETA:  0:13:10\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2749, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2748, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2747, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2747, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  27% |###########                                | ETA:  0:13:07\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3349, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3348, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3347, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3346, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  27% |###########                                | ETA:  0:13:03\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1390, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1390, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1390, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1389, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  28% |############                               | ETA:  0:12:59\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3756, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3756, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3754, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3753, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  28% |############                               | ETA:  0:12:56\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4167, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4167, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4165, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4163, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  28% |############                               | ETA:  0:12:52\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4024, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4023, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4022, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4020, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  29% |############                               | ETA:  0:12:49\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1590, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1590, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1589, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1588, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  29% |############                               | ETA:  0:12:46\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1554, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1554, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1553, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1553, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  29% |############                               | ETA:  0:12:44\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3245, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3244, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3244, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3243, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  30% |############                               | ETA:  0:12:41\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3742, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3742, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3740, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3739, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Episode: 90, score: 0.028500\n",
      "[0.         0.         0.22999999 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.16       0.         0.         0.\n",
      " 0.18       0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  30% |#############                              | ETA:  0:12:38\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  30% |#############                              | ETA:  0:12:36\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0764, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0764, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0764, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0763, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  31% |#############                              | ETA:  0:12:32\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3471, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3470, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3468, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3467, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  31% |#############                              | ETA:  0:12:28\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2909, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2909, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2909, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2908, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  31% |#############                              | ETA:  0:12:25\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1473, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1473, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1472, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1472, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  32% |#############                              | ETA:  0:12:21\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4280, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4279, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4277, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4275, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  32% |#############                              | ETA:  0:12:18\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3895, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3895, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3894, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3892, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  32% |##############                             | ETA:  0:12:14\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3729, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3728, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3726, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3725, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  33% |##############                             | ETA:  0:12:11\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2851, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2850, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2849, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2847, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  33% |##############                             | ETA:  0:12:08\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1773, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1773, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1772, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1772, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Episode: 100, score: 0.010500\n",
      "[0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.21 0.   0.   0.   0.   0.  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  33% |##############                             | ETA:  0:12:04\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1858, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1858, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1857, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1856, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  34% |##############                             | ETA:  0:12:01\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2590, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2589, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2588, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2587, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  34% |##############                             | ETA:  0:11:57\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3347, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3347, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3346, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3345, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  34% |##############                             | ETA:  0:11:54\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2043, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2042, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2042, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2041, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  35% |###############                            | ETA:  0:11:51\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4129, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4128, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4126, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4125, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  35% |###############                            | ETA:  0:11:47\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2386, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2386, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2386, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2385, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  35% |###############                            | ETA:  0:11:44\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3848, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3847, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3846, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3845, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  36% |###############                            | ETA:  0:11:40\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3170, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3169, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3167, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3166, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  36% |###############                            | ETA:  0:11:37\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  36% |###############                            | ETA:  0:11:33\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2074, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2074, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2073, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2073, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Episode: 110, score: 0.004500\n",
      "[0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.09]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  37% |###############                            | ETA:  0:11:30\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3033, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3032, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3031, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3030, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  37% |################                           | ETA:  0:11:27\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4619, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4618, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4616, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4614, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  37% |################                           | ETA:  0:11:23\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1354, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1354, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1354, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1353, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  38% |################                           | ETA:  0:11:20\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2713, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2712, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2711, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2711, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  38% |################                           | ETA:  0:11:16\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  38% |################                           | ETA:  0:11:13\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2268, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2267, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2266, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2266, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  39% |################                           | ETA:  0:11:09\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3286, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3286, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3285, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3284, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  39% |################                           | ETA:  0:11:06\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  39% |#################                          | ETA:  0:11:02\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2373, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2373, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2372, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2371, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  40% |#################                          | ETA:  0:10:58\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2842, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2842, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2841, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2840, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Episode: 120, score: 0.024500\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.48999999 0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  40% |#################                          | ETA:  0:10:55\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4041, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4040, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4039, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4038, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  40% |#################                          | ETA:  0:10:51\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1707, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1707, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1707, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1706, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  41% |#################                          | ETA:  0:10:47\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1749, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1749, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1748, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1747, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  41% |#################                          | ETA:  0:10:44\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0931, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0931, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0930, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0930, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  41% |#################                          | ETA:  0:10:40\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1123, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1123, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1123, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1122, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  42% |##################                         | ETA:  0:10:36\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0884, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0884, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0884, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0883, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  42% |##################                         | ETA:  0:10:32\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1736, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1735, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1735, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1734, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  42% |##################                         | ETA:  0:10:29\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2489, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2489, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2488, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2487, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  43% |##################                         | ETA:  0:10:25\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1890, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1890, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1889, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1889, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  43% |##################                         | ETA:  0:10:22\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0368, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0368, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0368, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0368, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Episode: 130, score: 0.005000\n",
      "[0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0. ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  43% |##################                         | ETA:  0:10:18\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1789, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1789, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1788, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1787, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  44% |##################                         | ETA:  0:10:14\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1481, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1481, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1480, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1480, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  44% |###################                        | ETA:  0:10:11\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3292, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3292, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3291, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3290, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  44% |###################                        | ETA:  0:10:08\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3254, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3254, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3252, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3251, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  45% |###################                        | ETA:  0:10:04\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2907, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2907, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2906, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2905, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  45% |###################                        | ETA:  0:10:01\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3116, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3116, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3114, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3113, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  45% |###################                        | ETA:  0:09:57\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0912, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0912, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0912, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0912, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  46% |###################                        | ETA:  0:09:54\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1149, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1149, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1149, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1148, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  46% |###################                        | ETA:  0:09:50\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0618, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0618, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0619, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0618, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  46% |####################                       | ETA:  0:09:47\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1742, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1742, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1742, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1741, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Episode: 140, score: 0.016000\n",
      "[0.   0.12 0.   0.   0.   0.   0.   0.2  0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  47% |####################                       | ETA:  0:09:43\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0841, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0841, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0841, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0841, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  47% |####################                       | ETA:  0:09:39\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3638, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3637, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3636, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3635, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  47% |####################                       | ETA:  0:09:36\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4161, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4160, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4159, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4158, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  48% |####################                       | ETA:  0:09:32\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3478, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3477, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3476, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3475, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  48% |####################                       | ETA:  0:09:28\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1975, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1975, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1974, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1974, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  48% |####################                       | ETA:  0:09:24\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  49% |#####################                      | ETA:  0:09:21\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0304, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0304, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0304, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0304, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  49% |#####################                      | ETA:  0:09:17\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2039, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2039, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2038, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2038, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  49% |#####################                      | ETA:  0:09:13\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2929, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2929, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2928, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2927, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  50% |#####################                      | ETA:  0:09:09\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2855, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2854, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2853, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2852, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Episode: 150, score: 0.015500\n",
      "[0.11 0.   0.   0.   0.   0.2  0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  50% |#####################                      | ETA:  0:09:06\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3105, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3104, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3104, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3103, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  50% |#####################                      | ETA:  0:09:02\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1397, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1397, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1397, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1396, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  51% |#####################                      | ETA:  0:08:58\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1604, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1604, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1604, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1603, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  51% |######################                     | ETA:  0:08:54\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  51% |######################                     | ETA:  0:08:51\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1963, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1962, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1962, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1961, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  52% |######################                     | ETA:  0:08:47\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2689, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2689, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2688, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2688, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  52% |######################                     | ETA:  0:08:43\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0741, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0741, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0741, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0741, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  52% |######################                     | ETA:  0:08:39\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3159, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3159, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3158, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3157, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  53% |######################                     | ETA:  0:08:36\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3212, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3211, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3210, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3209, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  53% |######################                     | ETA:  0:08:32\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3588, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3587, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3585, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3584, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Episode: 160, score: 0.026500\n",
      "[0.   0.   0.   0.   0.13 0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.21 0.   0.   0.   0.19 0.  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  53% |#######################                    | ETA:  0:08:28\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3166, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3166, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3165, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3165, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  54% |#######################                    | ETA:  0:08:24\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  54% |#######################                    | ETA:  0:08:21\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2169, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2168, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2168, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2167, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  54% |#######################                    | ETA:  0:08:17\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2915, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2914, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2914, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2913, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  55% |#######################                    | ETA:  0:08:13\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  55% |#######################                    | ETA:  0:08:10\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3192, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3192, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3191, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3190, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  55% |#######################                    | ETA:  0:08:06\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0190, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0190, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0190, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0190, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  56% |########################                   | ETA:  0:08:02\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1604, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1603, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1603, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1602, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  56% |########################                   | ETA:  0:07:58\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0978, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0978, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0977, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0977, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  56% |########################                   | ETA:  0:07:55\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1372, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1371, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1371, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1371, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Episode: 170, score: 0.020000\n",
      "[0.22999999 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.17       0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  57% |########################                   | ETA:  0:07:51\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2853, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2853, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2851, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2850, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  57% |########################                   | ETA:  0:07:47\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  57% |########################                   | ETA:  0:07:44\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3022, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3022, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3021, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3020, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  58% |########################                   | ETA:  0:07:40\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3996, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3997, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3996, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3992, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  58% |#########################                  | ETA:  0:07:36\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  58% |#########################                  | ETA:  0:07:32\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1079, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1079, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1078, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1078, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  59% |#########################                  | ETA:  0:07:29\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  59% |#########################                  | ETA:  0:07:25\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3391, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3390, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3388, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3387, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  59% |#########################                  | ETA:  0:07:21\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1215, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1215, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1215, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1214, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  60% |#########################                  | ETA:  0:07:18\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2518, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2518, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2517, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2516, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Episode: 180, score: 0.014500\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.28999999 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  60% |#########################                  | ETA:  0:07:14\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0373, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0373, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0373, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0373, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  60% |##########################                 | ETA:  0:07:10\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1110, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1110, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1109, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1109, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  61% |##########################                 | ETA:  0:07:06\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3012, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3012, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3011, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3009, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  61% |##########################                 | ETA:  0:07:03\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1059, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1059, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1059, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1058, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  61% |##########################                 | ETA:  0:06:59\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0408, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  62% |##########################                 | ETA:  0:06:55\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1698, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1698, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1697, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1697, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  62% |##########################                 | ETA:  0:06:52\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0622, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0622, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0621, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0621, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  62% |##########################                 | ETA:  0:06:48\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3865, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3864, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3862, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3860, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  63% |###########################                | ETA:  0:06:44\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4341, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4341, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4340, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4337, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  63% |###########################                | ETA:  0:06:41\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2135, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2135, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2134, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2133, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Episode: 190, score: 0.030000\n",
      "[0.         0.07       0.         0.         0.         0.\n",
      " 0.         0.         0.35999999 0.04       0.         0.\n",
      " 0.         0.         0.         0.         0.13       0.\n",
      " 0.         0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  63% |###########################                | ETA:  0:06:37\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3971, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3971, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3970, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3968, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  64% |###########################                | ETA:  0:06:33\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2629, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2628, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2627, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2626, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  64% |###########################                | ETA:  0:06:30\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2580, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2580, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2579, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2579, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  64% |###########################                | ETA:  0:06:26\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4438, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4438, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4439, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4437, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  65% |###########################                | ETA:  0:06:22\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2711, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2718, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2710, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2715, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  65% |############################               | ETA:  0:06:19\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2963, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2966, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2961, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2963, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  65% |############################               | ETA:  0:06:15\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3650, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3652, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3649, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3648, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  66% |############################               | ETA:  0:06:11\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2584, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2586, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2583, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2584, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  66% |############################               | ETA:  0:06:08\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  66% |############################               | ETA:  0:06:04\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3828, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3828, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3826, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3825, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Episode: 200, score: 0.027000\n",
      "[0.         0.         0.         0.         0.         0.29999999\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.12       0.\n",
      " 0.         0.12      ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  67% |############################               | ETA:  0:06:00\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2191, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2191, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2189, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2188, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  67% |############################               | ETA:  0:05:57\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3851, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3851, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3849, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3848, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  67% |#############################              | ETA:  0:05:53\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3942, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3941, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3940, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3938, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  68% |#############################              | ETA:  0:05:49\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1510, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1509, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1509, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1508, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  68% |#############################              | ETA:  0:05:46\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  68% |#############################              | ETA:  0:05:42\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3762, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3761, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3759, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3758, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  69% |#############################              | ETA:  0:05:38\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1242, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1242, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1242, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1241, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  69% |#############################              | ETA:  0:05:35\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2836, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2836, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2835, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2834, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  69% |#############################              | ETA:  0:05:31\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4371, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4369, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4368, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4366, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  70% |##############################             | ETA:  0:05:27\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2523, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2522, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2521, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2519, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Episode: 210, score: 0.021000\n",
      "[0.13 0.   0.   0.   0.   0.   0.07 0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.22 0.   0.   0.  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  70% |##############################             | ETA:  0:05:24\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4480, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4478, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4477, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4475, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  70% |##############################             | ETA:  0:05:20\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0788, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0788, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0787, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0787, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  71% |##############################             | ETA:  0:05:16\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1012, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1011, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1011, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1011, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  71% |##############################             | ETA:  0:05:13\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3372, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3372, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3371, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3370, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  71% |##############################             | ETA:  0:05:09\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3199, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3198, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3197, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3196, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  72% |##############################             | ETA:  0:05:05\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  72% |###############################            | ETA:  0:05:02\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2995, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2995, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2994, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2993, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  72% |###############################            | ETA:  0:04:58\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3617, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3617, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3615, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3614, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  73% |###############################            | ETA:  0:04:54\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2549, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2549, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2548, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2548, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  73% |###############################            | ETA:  0:04:51\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3910, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3909, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3908, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3907, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Episode: 220, score: 0.009000\n",
      "[0.   0.   0.   0.   0.   0.02 0.   0.   0.1  0.   0.   0.   0.   0.\n",
      " 0.06 0.   0.   0.   0.   0.  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  73% |###############################            | ETA:  0:04:47\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3080, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3080, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3079, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3078, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  74% |###############################            | ETA:  0:04:43\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2928, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2928, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2927, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2926, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  74% |###############################            | ETA:  0:04:40\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1248, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1247, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1247, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1247, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  74% |################################           | ETA:  0:04:36\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2666, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2666, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2664, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2663, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  75% |################################           | ETA:  0:04:32\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1242, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1242, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1241, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1240, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  75% |################################           | ETA:  0:04:29\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2377, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2376, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2376, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2375, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  75% |################################           | ETA:  0:04:25\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4298, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4297, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4295, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4293, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  76% |################################           | ETA:  0:04:21\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0542, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0542, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0542, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0542, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  76% |################################           | ETA:  0:04:18\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2945, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2945, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2944, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2943, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  76% |################################           | ETA:  0:04:14\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2303, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2303, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2302, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2301, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Episode: 230, score: 0.008500\n",
      "[0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.17\n",
      " 0.   0.   0.   0.   0.   0.  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  77% |#################################          | ETA:  0:04:10\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2269, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2269, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2268, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2267, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  77% |#################################          | ETA:  0:04:07\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3580, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3579, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3578, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3577, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  77% |#################################          | ETA:  0:04:03\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2683, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2682, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2681, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2681, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  78% |#################################          | ETA:  0:03:59\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2181, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2181, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2180, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2179, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  78% |#################################          | ETA:  0:03:56\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2998, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2998, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2997, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2996, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  78% |#################################          | ETA:  0:03:52\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3355, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3355, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3353, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3352, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  79% |#################################          | ETA:  0:03:48\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3380, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3380, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3379, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3379, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  79% |##################################         | ETA:  0:03:45\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2724, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2724, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2723, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2722, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  79% |##################################         | ETA:  0:03:41\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1255, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1255, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1254, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1253, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  80% |##################################         | ETA:  0:03:38\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2257, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2257, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2256, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2255, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Episode: 240, score: 0.016000\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.25999999 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.06      ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  80% |##################################         | ETA:  0:03:34\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1178, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1178, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1178, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1177, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  80% |##################################         | ETA:  0:03:30\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2787, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2787, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2786, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2785, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  81% |##################################         | ETA:  0:03:27\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2120, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2120, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2119, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2118, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  81% |##################################         | ETA:  0:03:23\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0923, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0922, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0922, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0922, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  81% |###################################        | ETA:  0:03:19\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3410, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3409, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3408, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3407, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  82% |###################################        | ETA:  0:03:16\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3374, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3373, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3372, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3371, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  82% |###################################        | ETA:  0:03:12\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2451, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2450, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2449, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2448, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  82% |###################################        | ETA:  0:03:08\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0892, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0892, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0892, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0891, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  83% |###################################        | ETA:  0:03:05\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4296, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4295, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4294, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4292, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  83% |###################################        | ETA:  0:03:01\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1532, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1531, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1531, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1531, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Episode: 250, score: 0.006500\n",
      "[0.   0.   0.13 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  83% |###################################        | ETA:  0:02:58\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2875, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2874, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2873, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2872, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  84% |####################################       | ETA:  0:02:54\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2442, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2441, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2440, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2440, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  84% |####################################       | ETA:  0:02:50\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4803, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4801, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4799, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4796, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  84% |####################################       | ETA:  0:02:47\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3907, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3906, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3905, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3904, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  85% |####################################       | ETA:  0:02:43\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3272, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3272, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3270, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3269, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  85% |####################################       | ETA:  0:02:39\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2848, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2847, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2846, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2845, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  85% |####################################       | ETA:  0:02:36\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3651, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3650, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3648, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3647, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  86% |####################################       | ETA:  0:02:32\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3506, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3505, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3504, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3502, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  86% |#####################################      | ETA:  0:02:28\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3945, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3945, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3943, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3942, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  86% |#####################################      | ETA:  0:02:25\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2574, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2575, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2573, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2573, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Episode: 260, score: 0.016000\n",
      "[0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.18 0.   0.\n",
      " 0.   0.   0.   0.14 0.   0.  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  87% |#####################################      | ETA:  0:02:21\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2716, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2715, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2714, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2713, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  87% |#####################################      | ETA:  0:02:17\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2590, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2589, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2588, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2587, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  87% |#####################################      | ETA:  0:02:14\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2886, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2885, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2885, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2884, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  88% |#####################################      | ETA:  0:02:10\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2692, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2692, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2691, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2690, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  88% |#####################################      | ETA:  0:02:07\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2127, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2127, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2126, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2125, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  88% |######################################     | ETA:  0:02:03\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2746, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2745, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2745, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2744, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  89% |######################################     | ETA:  0:01:59\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2124, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2123, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2122, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2122, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  89% |######################################     | ETA:  0:01:56\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1883, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1882, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1882, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1881, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  89% |######################################     | ETA:  0:01:52\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3064, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3063, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3062, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3061, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  90% |######################################     | ETA:  0:01:48\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "Episode: 270, score: 0.000000\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  90% |######################################     | ETA:  0:01:45\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0901, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0901, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0901, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0900, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  90% |######################################     | ETA:  0:01:41\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0343, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0342, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0342, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0342, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  91% |#######################################    | ETA:  0:01:38\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3976, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3976, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3974, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3973, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  91% |#######################################    | ETA:  0:01:34\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2669, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2668, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2667, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2666, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  91% |#######################################    | ETA:  0:01:30\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3287, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3286, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3286, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3285, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  92% |#######################################    | ETA:  0:01:27\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2036, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2036, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2035, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2034, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  92% |#######################################    | ETA:  0:01:23\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2335, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2334, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2333, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2332, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  92% |#######################################    | ETA:  0:01:19\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2860, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2859, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2859, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2858, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  93% |#######################################    | ETA:  0:01:16\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1784, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1784, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1783, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1782, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  93% |########################################   | ETA:  0:01:12\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2894, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2893, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2892, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2891, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Episode: 280, score: 0.078000\n",
      "[0.         0.2        0.         0.26999999 0.11       0.\n",
      " 0.         0.         0.         0.         0.         0.05\n",
      " 0.         0.70999998 0.         0.         0.         0.22\n",
      " 0.         0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  93% |########################################   | ETA:  0:01:08\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3030, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3030, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3029, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3027, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  94% |########################################   | ETA:  0:01:05\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2404, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2403, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2402, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2401, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  94% |########################################   | ETA:  0:01:01\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3407, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3405, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3403, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3402, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  94% |########################################   | ETA:  0:00:58\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3228, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3228, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3227, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3226, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  95% |########################################   | ETA:  0:00:54\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4067, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4068, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4065, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4063, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  95% |########################################   | ETA:  0:00:50\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2642, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2643, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2641, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2641, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  95% |#########################################  | ETA:  0:00:47\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  96% |#########################################  | ETA:  0:00:43\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3738, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3737, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3736, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3735, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  96% |#########################################  | ETA:  0:00:39\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4689, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4688, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4686, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4684, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  96% |#########################################  | ETA:  0:00:36\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3163, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3163, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3162, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3161, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Episode: 290, score: 0.024000\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.07       0.         0.         0.31999999 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.09      ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  97% |#########################################  | ETA:  0:00:32\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3361, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3361, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3359, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3359, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  97% |#########################################  | ETA:  0:00:29\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2939, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2938, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2937, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2937, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  97% |#########################################  | ETA:  0:00:25\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2194, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2194, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2192, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2191, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  98% |########################################## | ETA:  0:00:21\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1634, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1634, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1634, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1633, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  98% |########################################## | ETA:  0:00:18\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2650, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2649, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2648, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2648, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  98% |########################################## | ETA:  0:00:14\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4261, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4259, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4257, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4255, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  99% |########################################## | ETA:  0:00:10\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1930, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1930, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1930, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1929, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  99% |########################################## | ETA:  0:00:07\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1313, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1312, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1312, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1312, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  99% |########################################## | ETA:  0:00:03\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1347, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1346, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1346, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1346, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop: 100% |###########################################| Time: 0:18:09\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0818, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0818, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0817, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0817, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Episode: 300, score: 0.011000\n",
      "[0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.22 0.\n",
      " 0.   0.   0.   0.   0.   0.  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# keep track of how long training takes\n",
    "# WARNING: running through all 800 episodes will take 30-45 minutes\n",
    "\n",
    "# training loop max iterations\n",
    "episode = 300\n",
    "\n",
    "# widget bar to display progress\n",
    "!pip install progressbar\n",
    "import progressbar as pb\n",
    "widget = ['training loop: ', pb.Percentage(), ' ', \n",
    "          pb.Bar(), ' ', pb.ETA() ]\n",
    "timer = pb.ProgressBar(widgets=widget, maxval=episode).start()\n",
    "\n",
    "discount_rate = .99\n",
    "epsilon = 0.2\n",
    "beta = .01\n",
    "tmax = 1000\n",
    "SGD_epoch = 4\n",
    "\n",
    "# keep track of progress\n",
    "mean_rewards = []\n",
    "\n",
    "for e in range(episode):\n",
    "    env_info = env.reset(train_mode=True)[brain_name]   \n",
    "    # collect trajectories\n",
    "    old_probs, states, actions, rewards = \\\n",
    "        collect_trajectories(env, policy, tmax=tmax)\n",
    "        \n",
    "    total_rewards = np.sum(rewards, axis=0)\n",
    "\n",
    "\n",
    "    # gradient ascent step\n",
    "    for _ in range(SGD_epoch):\n",
    "        \n",
    "        # uncomment to utilize your own clipped function!\n",
    "        # L = -clipped_surrogate(policy, old_probs, states, actions, rewards, epsilon=epsilon, beta=beta)\n",
    "\n",
    "        L = -clipped_surrogate(policy, old_probs, states, actions, rewards,\n",
    "                                          epsilon=epsilon, beta=beta)\n",
    "        print(L)\n",
    "        optimizer.zero_grad()\n",
    "        L.backward()\n",
    "        optimizer.step()\n",
    "        del L\n",
    "    \n",
    "    # the clipping parameter reduces as time goes on\n",
    "    epsilon*=.999\n",
    "    \n",
    "    # the regulation term also reduces\n",
    "    # this reduces exploration in later runs\n",
    "    beta*=.995\n",
    "    \n",
    "    # get the average reward of the parallel environments\n",
    "    mean_rewards.append(np.mean(total_rewards))\n",
    "    \n",
    "    # display some progress every 20 iterations\n",
    "    if (e+1)%10 ==0 :\n",
    "        print(\"Episode: {0:d}, score: {1:f}\".format(e+1,np.mean(total_rewards)))\n",
    "        print(total_rewards)\n",
    "        \n",
    "    # update progress widget bar\n",
    "    timer.update(e+1)\n",
    "    \n",
    "timer.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
